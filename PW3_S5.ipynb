{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"bc635afb677e4687a9d0adcbec313443":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aab97f3ab15a477d99a8c8a11b344a21","IPY_MODEL_3db71f895fb14e299feae15129121bc9","IPY_MODEL_c5ca115400b94302b7b11ac95bdda6f5"],"layout":"IPY_MODEL_b43231eca6f64699a5f3c6f97f97b552"}},"aab97f3ab15a477d99a8c8a11b344a21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_296ee7c03c924620a2200bcd0e4a9d43","placeholder":"​","style":"IPY_MODEL_5840b611679c4b77abbee61ac44cfe2b","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"3db71f895fb14e299feae15129121bc9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09ad626ab8ef4e3ab6e47d55a227a951","max":247723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9321b6fd451416db0f0a6f73c619c1e","value":247723}},"c5ca115400b94302b7b11ac95bdda6f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_860cd2cef2e1446e9d7942daf7681679","placeholder":"​","style":"IPY_MODEL_20c1659604a14ae397bee8ec4e413e5b","value":" 248k/248k [00:00&lt;00:00, 3.62MB/s]"}},"b43231eca6f64699a5f3c6f97f97b552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"296ee7c03c924620a2200bcd0e4a9d43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5840b611679c4b77abbee61ac44cfe2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09ad626ab8ef4e3ab6e47d55a227a951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9321b6fd451416db0f0a6f73c619c1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"860cd2cef2e1446e9d7942daf7681679":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20c1659604a14ae397bee8ec4e413e5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"689f1481d43b481dadc94f1a06d3cf42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84a83ea29c2348b3b7c33a36f82c15eb","IPY_MODEL_8267e34c84c0467e8366ee398df4c8ae","IPY_MODEL_7926125943b6485791246bd4e8cba33e"],"layout":"IPY_MODEL_2f489dfaad0f4d40b4bb00de6bf946ff"}},"84a83ea29c2348b3b7c33a36f82c15eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28ac73dd7cb746d6bb795fdd4f3f3582","placeholder":"​","style":"IPY_MODEL_43a37ae0aee1463f86d80f946762076c","value":"Downloading (…)cial_tokens_map.json: 100%"}},"8267e34c84c0467e8366ee398df4c8ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b73e1a38d70d4f2ca0adf436aaeb4aca","max":134,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df1a89b921f346e18bd784ffd1bfc60d","value":134}},"7926125943b6485791246bd4e8cba33e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9b40297e07345a7ad4265a02b123d70","placeholder":"​","style":"IPY_MODEL_aad1ac1e35044c96b16371b3b01165ca","value":" 134/134 [00:00&lt;00:00, 6.30kB/s]"}},"2f489dfaad0f4d40b4bb00de6bf946ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28ac73dd7cb746d6bb795fdd4f3f3582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43a37ae0aee1463f86d80f946762076c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b73e1a38d70d4f2ca0adf436aaeb4aca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df1a89b921f346e18bd784ffd1bfc60d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9b40297e07345a7ad4265a02b123d70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad1ac1e35044c96b16371b3b01165ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6ee85dde0984ea1a06a2adfeef7e6d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dbc77d8b0904845a91f0ec03e324ae7","IPY_MODEL_2007b24df4ce47eeb0e7da66ad9c9e79","IPY_MODEL_c86b0328eade44ac8f8af384ecf3ba7a"],"layout":"IPY_MODEL_b0e9d6fa7d6f4099902c941436841c32"}},"4dbc77d8b0904845a91f0ec03e324ae7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_894e014b9cb54423853a277ec8ae5ee1","placeholder":"​","style":"IPY_MODEL_ebd86257bc0e44d7b6178c2283f76136","value":"Downloading (…)okenizer_config.json: 100%"}},"2007b24df4ce47eeb0e7da66ad9c9e79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfd542a5db2640d3be5454c6c4a896bc","max":310,"min":0,"orientation":"horizontal","style":"IPY_MODEL_986766112c2143b1ad388d1a469fdb81","value":310}},"c86b0328eade44ac8f8af384ecf3ba7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bc4a698b7644dbb8dd1ab74a4a30cb4","placeholder":"​","style":"IPY_MODEL_f99c6d7a3a834aee880f7296a793d53a","value":" 310/310 [00:00&lt;00:00, 11.2kB/s]"}},"b0e9d6fa7d6f4099902c941436841c32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894e014b9cb54423853a277ec8ae5ee1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebd86257bc0e44d7b6178c2283f76136":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfd542a5db2640d3be5454c6c4a896bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"986766112c2143b1ad388d1a469fdb81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7bc4a698b7644dbb8dd1ab74a4a30cb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f99c6d7a3a834aee880f7296a793d53a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"948ed599096d4d84a3ad74544ed51645":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d10234ca3b8a4c3183462762f9aa2613","IPY_MODEL_a35426e320b34bdab47725d6880298a7","IPY_MODEL_12df168bb8e5441882cd6d6b8663e19c"],"layout":"IPY_MODEL_ed21ce907689443aa988b43a10e3167b"}},"d10234ca3b8a4c3183462762f9aa2613":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23d462af20b24ac1b0eaa3315d1f04fc","placeholder":"​","style":"IPY_MODEL_9fa50e6223164ff0b8890742f556fda5","value":"Downloading (…)lve/main/config.json: 100%"}},"a35426e320b34bdab47725d6880298a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c54b5732d3844826bc990c756132ecd3","max":650,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cefabe2180154ce884440caa77c3bbd9","value":650}},"12df168bb8e5441882cd6d6b8663e19c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b95a2e1f69493fa23f557b9725ae60","placeholder":"​","style":"IPY_MODEL_12faf652a4884623a8bfd698f46eb2ec","value":" 650/650 [00:00&lt;00:00, 15.6kB/s]"}},"ed21ce907689443aa988b43a10e3167b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23d462af20b24ac1b0eaa3315d1f04fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa50e6223164ff0b8890742f556fda5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c54b5732d3844826bc990c756132ecd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cefabe2180154ce884440caa77c3bbd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8b95a2e1f69493fa23f557b9725ae60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12faf652a4884623a8bfd698f46eb2ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7beb0a98db494a4a912b92673e84dfcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b64025f5904a4fc8933017b6f65c06b3","IPY_MODEL_60750663a1fa4e17bc392d9780b9ac43","IPY_MODEL_2b5e8d65e2b3496883a3262d067c339b"],"layout":"IPY_MODEL_0fe200ff8ee541f1ab553a7491a35526"}},"b64025f5904a4fc8933017b6f65c06b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd6f9afa81084f2d9c92a15f12512090","placeholder":"​","style":"IPY_MODEL_7d5732251506465d94534cf3c97ff089","value":"Downloading pytorch_model.bin: 100%"}},"60750663a1fa4e17bc392d9780b9ac43":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_834ca82338b6409d99d56a9dfcbdfecc","max":439621341,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17b6e12231a645da96bd0f07806f7083","value":439621341}},"2b5e8d65e2b3496883a3262d067c339b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_683ba0531bd9462eb45e5524928f4739","placeholder":"​","style":"IPY_MODEL_0c8d5714fe3d4c96803588064835c11b","value":" 440M/440M [00:02&lt;00:00, 180MB/s]"}},"0fe200ff8ee541f1ab553a7491a35526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd6f9afa81084f2d9c92a15f12512090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d5732251506465d94534cf3c97ff089":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"834ca82338b6409d99d56a9dfcbdfecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17b6e12231a645da96bd0f07806f7083":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"683ba0531bd9462eb45e5524928f4739":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c8d5714fe3d4c96803588064835c11b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Practical Work 3\n","## Session 5: BETO and RoBERTa (Spanish) for text classification tasks.\n","\n","- José Baixauli\n","- Kexin Jiang\n","- José Fco. Olivert\n","\n","The goal of this lab session is to help students understand and gain\n","practice in the use of deep learning-based language models, in particular\n","transformer-based models (BERT, BETO and RoBERTa). The second\n","objective is the application of these models to text classification tasks,\n","particularly for the HUHU shared task."],"metadata":{"id":"2OseQaJA0UAo"}},{"cell_type":"markdown","source":["### Importing all the libraries and packages"],"metadata":{"id":"jzd9ywPu0tFb"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":579,"referenced_widgets":["bc635afb677e4687a9d0adcbec313443","aab97f3ab15a477d99a8c8a11b344a21","3db71f895fb14e299feae15129121bc9","c5ca115400b94302b7b11ac95bdda6f5","b43231eca6f64699a5f3c6f97f97b552","296ee7c03c924620a2200bcd0e4a9d43","5840b611679c4b77abbee61ac44cfe2b","09ad626ab8ef4e3ab6e47d55a227a951","d9321b6fd451416db0f0a6f73c619c1e","860cd2cef2e1446e9d7942daf7681679","20c1659604a14ae397bee8ec4e413e5b","689f1481d43b481dadc94f1a06d3cf42","84a83ea29c2348b3b7c33a36f82c15eb","8267e34c84c0467e8366ee398df4c8ae","7926125943b6485791246bd4e8cba33e","2f489dfaad0f4d40b4bb00de6bf946ff","28ac73dd7cb746d6bb795fdd4f3f3582","43a37ae0aee1463f86d80f946762076c","b73e1a38d70d4f2ca0adf436aaeb4aca","df1a89b921f346e18bd784ffd1bfc60d","f9b40297e07345a7ad4265a02b123d70","aad1ac1e35044c96b16371b3b01165ca","f6ee85dde0984ea1a06a2adfeef7e6d3","4dbc77d8b0904845a91f0ec03e324ae7","2007b24df4ce47eeb0e7da66ad9c9e79","c86b0328eade44ac8f8af384ecf3ba7a","b0e9d6fa7d6f4099902c941436841c32","894e014b9cb54423853a277ec8ae5ee1","ebd86257bc0e44d7b6178c2283f76136","bfd542a5db2640d3be5454c6c4a896bc","986766112c2143b1ad388d1a469fdb81","7bc4a698b7644dbb8dd1ab74a4a30cb4","f99c6d7a3a834aee880f7296a793d53a","948ed599096d4d84a3ad74544ed51645","d10234ca3b8a4c3183462762f9aa2613","a35426e320b34bdab47725d6880298a7","12df168bb8e5441882cd6d6b8663e19c","ed21ce907689443aa988b43a10e3167b","23d462af20b24ac1b0eaa3315d1f04fc","9fa50e6223164ff0b8890742f556fda5","c54b5732d3844826bc990c756132ecd3","cefabe2180154ce884440caa77c3bbd9","a8b95a2e1f69493fa23f557b9725ae60","12faf652a4884623a8bfd698f46eb2ec"]},"id":"ZwDKYNjVB2Z-","executionInfo":{"status":"ok","timestamp":1684840408574,"user_tz":-120,"elapsed":21874,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"bbeec5c1-092b-4785-e5d6-63444cad1962"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc635afb677e4687a9d0adcbec313443"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"689f1481d43b481dadc94f1a06d3cf42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6ee85dde0984ea1a06a2adfeef7e6d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"948ed599096d4d84a3ad74544ed51645"}},"metadata":{}}],"source":["!pip install transformers\n","import numpy as np\n","import pandas as pd\n","from transformers import  AdamW,BertModel,BertTokenizer,RobertaTokenizer,RobertaModel\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","import copy\n","import warnings\n","from sklearn.metrics import accuracy_score as acc\n","from sklearn.metrics import f1_score as f1\n","import torch.optim as optim\n","\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device\n","\n","tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")"]},{"cell_type":"markdown","source":["We create the tokenizer too. This BERT tokenizer will help us to transform the text and train the model\n"],"metadata":{"id":"fyTSX21J2N7i"}},{"cell_type":"markdown","source":["## Reading the data\n","\n","We will use \"train.csv\" dataset that contains the raw text of the tweet and different variables. \n","\n","We will use just the text of the tweet and the variable \"humor\" since we are going to fine tune a transformer for binary classification in order to predict this *label*"],"metadata":{"id":"xIU0YNE40xGF"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_FPC8TIOsqNF","executionInfo":{"status":"ok","timestamp":1684840423151,"user_tz":-120,"elapsed":14585,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"499cf5e2-40bc-436f-dd48-af85c28ffa73"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data = pd.read_csv(\"/content/drive/MyDrive/transformer/train.csv\")"],"metadata":{"id":"jS4NFAlP2Qr2","executionInfo":{"status":"ok","timestamp":1684840423152,"user_tz":-120,"elapsed":6,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"XLwkmHCCLSOq","executionInfo":{"status":"ok","timestamp":1684603328994,"user_tz":-120,"elapsed":9,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"19454638-716c-4950-840e-f1a91b3f2236"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      index                                              tweet  humor  \\\n","0     72157  Mi celular tiene una aplicación que te hace ve...      1   \n","1     68084  En esta vida me tocó tener mala suerte, espero...      1   \n","2     69089  Tu mamá es taaan taan obesa, que cuando pasa f...      1   \n","3     69190  Mi tía me dijo: \\n- tengo memoria de Elefante....      1   \n","4     70474  - Mamá, en el colegio me dicen gorda.\\n- ¡Ay M...      1   \n","...     ...                                                ...    ...   \n","2666  41280  Un claro ejemplo más del vacío moral de las fe...      0   \n","2667   2166  MENTION Vamos a preguntar a las feminazis. Par...      0   \n","2668  39933  Si tuviera tetas y subiera fotos picantes, al ...      0   \n","2669   4992  qtagarre dl culo ynotarle toda lapolla ay bien...      0   \n","2670  36927  Claro, Internet lo que merece son fotos de tus...      0   \n","\n","      prejudice_woman  prejudice_lgbtiq  prejudice_inmigrant_race  gordofobia  \\\n","0                   0                 0                         0           1   \n","1                   0                 0                         0           1   \n","2                   0                 0                         0           1   \n","3                   0                 0                         0           1   \n","4                   0                 0                         0           1   \n","...               ...               ...                       ...         ...   \n","2666                1                 0                         0           0   \n","2667                1                 0                         0           0   \n","2668                1                 0                         0           0   \n","2669                1                 0                         0           0   \n","2670                1                 0                         0           0   \n","\n","      mean_prejudice  \n","0                3.0  \n","1                2.8  \n","2                3.6  \n","3                3.4  \n","4                3.0  \n","...              ...  \n","2666             3.4  \n","2667             3.8  \n","2668             4.0  \n","2669             3.8  \n","2670             3.4  \n","\n","[2671 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-b7ee6eae-99b4-422f-b265-aa450b466b1d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>tweet</th>\n","      <th>humor</th>\n","      <th>prejudice_woman</th>\n","      <th>prejudice_lgbtiq</th>\n","      <th>prejudice_inmigrant_race</th>\n","      <th>gordofobia</th>\n","      <th>mean_prejudice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>72157</td>\n","      <td>Mi celular tiene una aplicación que te hace ve...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>68084</td>\n","      <td>En esta vida me tocó tener mala suerte, espero...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2.8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>69089</td>\n","      <td>Tu mamá es taaan taan obesa, que cuando pasa f...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3.6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>69190</td>\n","      <td>Mi tía me dijo: \\n- tengo memoria de Elefante....</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3.4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>70474</td>\n","      <td>- Mamá, en el colegio me dicen gorda.\\n- ¡Ay M...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2666</th>\n","      <td>41280</td>\n","      <td>Un claro ejemplo más del vacío moral de las fe...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.4</td>\n","    </tr>\n","    <tr>\n","      <th>2667</th>\n","      <td>2166</td>\n","      <td>MENTION Vamos a preguntar a las feminazis. Par...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.8</td>\n","    </tr>\n","    <tr>\n","      <th>2668</th>\n","      <td>39933</td>\n","      <td>Si tuviera tetas y subiera fotos picantes, al ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>2669</th>\n","      <td>4992</td>\n","      <td>qtagarre dl culo ynotarle toda lapolla ay bien...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.8</td>\n","    </tr>\n","    <tr>\n","      <th>2670</th>\n","      <td>36927</td>\n","      <td>Claro, Internet lo que merece son fotos de tus...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2671 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7ee6eae-99b4-422f-b265-aa450b466b1d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b7ee6eae-99b4-422f-b265-aa450b466b1d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b7ee6eae-99b4-422f-b265-aa450b466b1d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["We divide the dataset intro training and testing in order to see later the performance of our model."],"metadata":{"id":"QBhT_Lu71pRZ"}},{"cell_type":"code","source":["inputs = data[\"tweet\"]\n","labels = data[\"humor\"]\n","\n","\n","\n","train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n","    inputs, \n","    labels, \n","    test_size=0.2, \n","    stratify=labels\n",")\n"],"metadata":{"id":"qE7Ol36ICDeg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lbvsktht5a76","executionInfo":{"status":"ok","timestamp":1684598539713,"user_tz":-120,"elapsed":208,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"83f16632-cc24-473a-8027-3e0f3dbfbfa5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1285                         MENTION gitanos d to la vida\n","1664                  En ámbito  Lgtbi   no es aplicable!\n","324     Un poco de humor negro (La pierna está complet...\n","538     MENTION Pero se enfadan si las llamamos femina...\n","393     MENTION ¿De qué hablas? Se la pasan hablando d...\n","                              ...                        \n","453     si un gay le dice a otro \"que te den por el cu...\n","1314    MENTION MENTION Mientras tanto tú estás de pas...\n","1055              MAS XENOFOBO QUE AYER\\nMENOS QUE MAÑANA\n","488     Las feministas tienen clara su prioridad: \\n\\n...\n","1379    MENTION Y va a resultar que el diablo es negro...\n","Name: tweet, Length: 2136, dtype: object"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["## DATASET CLASS\n","\n","This class recieves a set of tweets ,its respective labels and the max_len of the tweets, in our case we used 60 as we will see later. Also recieves a tokenizer that will transform the tweets to \"inputs_id\" and \"attention_mask\", that are the two variables that will feed our model. The output of this class will be a dataloader dividing the train set and the test set in batches, containing the raw text of he tweet, the \"inputs_id\" of the tweet, the \"attention_mask\" and the target (the label). This batches will be of 64 observations. this will make our training process more efficient because the parameters of the model will be easier to optimize."],"metadata":{"id":"CLisOaQQ10AG"}},{"cell_type":"code","source":["class createDataset(Dataset):\n","\n","    def __init__(self, texts, targets, tokenizer, max_len):\n","        self.texts = texts\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","  \n","    def __len__(self):\n","        return len(self.texts)\n","  \n","    def __getitem__(self, item):\n","        \n","        text = self.texts[item]\n","        target = self.targets[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","        )\n","        input=encoding['input_ids'].flatten()\n","        \n","\n","        return {\n","            'text': text,\n","            'input_ids': input,\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'targets': torch.tensor(target, dtype=torch.long)\n","        }\n","\n","def create_data_loader(texts, labels, tokenizer, max_len, batch_size):\n","    \n","    ds = createDataset(\n","        texts=texts.to_numpy(),\n","        targets=labels.to_numpy(),\n","        \n","        tokenizer=tokenizer,\n","        max_len=max_len\n","  )\n","\n","    return DataLoader(\n","        ds,\n","        batch_size=batch_size,\n","        num_workers=4\n","      )"],"metadata":{"id":"XGqh4kKYCP90"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MODEL CLASS\n","\n","This class is composed by two functions.\n","1. __init__ : This class builds the structure of the model. First we have the BETO model as the first layer. Then we have linear layer such as linears, dropouts, ReLU and Softmax.\n","2. __forward__ : This function is in charge of returning the outputs. The input to this function is the inputs_id and the attention_max of each observation of the batch. This will go into the BETO model that returns the 768 components of the embedding of each tweet. Then we will perform a Linear layer in order to reduce the dimensionality, from 768 to 192. Later, we will make a dropout to avoid overfitting and turning off some random parameters of the model. Then we will perform a ReLU in order to find non-linear relationships. We will perfomr a dropout again and finally we will perform another Linear, from 192 to 2 and then a Softmax because we are in a classification task."],"metadata":{"id":"rZVmEKe53KAN"}},{"cell_type":"markdown","source":["### Two possible models:\n","- bertin-project/bertin-roberta-base-spanish\n","- dccuchile/bert-base-spanish-wwm-uncased ***Better performance**"],"metadata":{"id":"mbFQPpRiy9-b"}},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self, latent_dims,max_len,nhid):\n","        super(Model, self).__init__()\n","\n","        \n","        self.roberta = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n","        self.linear = nn.Linear(in_features=768, out_features=192)\n","        self.dropout=nn.Dropout(0.2)\n","        self.r = nn.ReLU()\n","        self.l = nn.Linear(in_features=192,out_features=2)\n","        self.s = nn.Softmax(dim=1)\n","        \n","\n","        self.latent_dims=latent_dims\n","        self.nhid=nhid\n","\n","\n","    def forward(self, input_id,attention):\n","\n","      secuence_output = self.roberta(\n","            input_ids=input_id,\n","            attention_mask=attention\n","        )\n","      \n","      o = secuence_output.pooler_output\n","\n","      o=self.linear(o)\n","      o=self.dropout(o)\n","      o=self.r(o)\n","      o=self.l(o)\n","      o=self.dropout(o)\n","      o = self.s(o)\n","\n","  \n","      \n","      return o\n","\n"],"metadata":{"id":"60_UHNBKGnbv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inicializing parameters.\n","We will use as loss function CrossEntropyLoss but another option is to use BCEloss. The batch size is 64 as commented before and the learning rate will be 0.00001. After different tests those parameters gave our model the best performance."],"metadata":{"id":"DDlqI_cS4vTI"}},{"cell_type":"code","source":["batch_size = 64\n","learning_rate = 0.00001\n","criterion = nn.CrossEntropyLoss().to(device)\n","criterion.requires_grad=True\n","epochs = 8\n","latentdims=2\n","nhid=128\n","max_len=60\n"],"metadata":{"id":"yARD2D70YOfW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### We create the model and the optimizer, then we will put our model in the GPU in order to obtain better performance"],"metadata":{"id":"ZOY7B7Pz5KIx"}},{"cell_type":"code","source":["model= Model(latentdims,max_len,nhid)\n","\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","model.to(device)"],"metadata":{"id":"eLaFw27XNtxs","executionInfo":{"status":"ok","timestamp":1684598863318,"user_tz":-120,"elapsed":2508,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9292a7ef-f809-4e49-a8d9-b043dc269a93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (roberta): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (tanh): Tanh()\n","  (linear): Linear(in_features=768, out_features=192, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (r): ReLU()\n","  (l): Linear(in_features=192, out_features=2, bias=True)\n","  (s): Softmax(dim=1)\n",")"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["### We create our train data loader and test data loader to train the model and test it."],"metadata":{"id":"XQL25CQv5T_x"}},{"cell_type":"code","source":["train_data_loader = create_data_loader(train_inputs, train_labels,tokenizer, max_len, batch_size)\n","\n","test_data_loader = create_data_loader(test_inputs, test_labels, tokenizer, max_len, batch_size)"],"metadata":{"id":"LK5xnezKYtOV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training function\n","\n","This function recieves the model the train data loader, the test data loader, the loss function and the optimizer. For each bacth of the train test it will sustract the inputs, the attention and the labels. Then it will feed the model with those variables and get an output. We will compute the loss with the output and the target and we will back propagate it for the next iteration. Then we compute the training accuracy and the training f1. Then we turn off all the gradients and we just predict the test set. We compute the accuracy and f1 of test and we show the results for each epoch."],"metadata":{"id":"eSYKnGUP5bqJ"}},{"cell_type":"code","source":["def train_an_epoch(\n","    model, \n","    train_data_loader,\n","    dev_data_loader,\n","    criterion, \n","    optimizer\n","):\n","\n","    \n","\n","    # These are the metrics that will indicate us how well it's doing the model...\n","    running_loss = 0\n","    training_acc=[]\n","    f1_training=[]\n","    steps = 0;\n","    \n","    for batch in train_data_loader:\n","        \n","        b=len(batch[\"input_ids\"])\n","        # Clean gradients...\n","        optimizer.zero_grad()\n","    \n","        # Get the information from the tokenization... (using GPU)\n","        input_ids = batch[\"input_ids\"].to(device)\n","        targets = batch[\"targets\"].to(device)\n","        attention = batch[\"attention_mask\"].to(device)\n","\n","        # get the model's predictions...\n","        outputs = model(\n","            input_ids,\n","            attention\n","            \n","        )\n","\n","        # Apply the loss function and the perform backward propagation...\n","       \n","        loss = criterion(outputs, targets)\n","       \n","        loss.backward() \n","        optimizer.step()\n","        \n","        # update the metrics...\n","\n","        pred = []\n","        real=[]\n","        for output in outputs:\n","          zero=output[0].item()\n","          one=output[1].item()\n","          if zero > one:\n","            pred.append(0)\n","          else:\n","            pred.append(1)\n","\n","        for t in targets:\n","\n","          real.append(t.item())\n","\n","        bacc=acc(real,pred)\n","        bf1= f1(real,pred)\n","        running_loss+=loss.item()\n","        training_acc.append(bacc)\n","        f1_training.append(bf1)\n","\n","        steps+=1\n","            \n","    # get the mean of the metrics...\n","    \n","    loss = running_loss/steps;\n","    t_acc=sum(training_acc)/len(training_acc)\n","    t_f1=sum(f1_training)/len(f1_training)\n","    \n","    \n","    \n","    # evaluate the model with the validation data set \n","    # (\"turn off\" gradients...)\n","    with torch.no_grad():\n","        \n","        # These are the metrics that will indicate us how well it's doing the model...\n","        test_acc=[];\n","        steps_val=0;\n","        f1_test=[]\n","        \n","        for batch in dev_data_loader:\n","\n","            b= len(batch[\"input_ids\"])\n","            \n","            # Get the information from the tokenization... (using GPU)\n","            input_ids = batch[\"input_ids\"].to(device)\n","            targets = batch[\"targets\"].to(device)\n","            attention = batch[\"attention_mask\"].to(device)\n","\n","            # get the model's predictions...\n","            outputs = model(\n","                input_ids,\n","                attention\n","                \n","                \n","            )\n","            \n","            pred = []\n","            real=[]\n","            for output in outputs:\n","              zero=output[0].item()\n","              one=output[1].item()\n","              if zero > one:\n","                pred.append(0)\n","              else:\n","                pred.append(1)\n","\n","            for t in targets:\n","\n","              real.append(t.item())\n","\n","            bacc=acc(real,pred)\n","            bf1= f1(real,pred)\n","            test_acc.append(bacc)\n","            f1_test.append(bf1)\n","\n","\n","        v_acc=sum(test_acc)/len(test_acc)\n","        v_f1= sum(f1_test)/len(f1_test)\n","    \n","\n","    return loss,t_acc,v_acc,t_f1,v_f1\n","\n","def train_the_model(epochs):\n","    \n","    for e in range(epochs):\n","      #, acc, val_acc\n","        \n","        loss,t_acc,v_acc,t_f1,v_f1 = train_an_epoch(\n","            model, \n","            train_data_loader,\n","            test_data_loader,\n","            criterion, \n","            optimizer\n","        )\n","        \n","        print('--------EPOCH SUMMARY---------')\n","        print('Epoch ', e+1, ' training loss: ', loss)\n","        print('Epoch ', e+1, ' training acc: ', t_acc*100, '%')\n","        print('Epoch ', e+1, ' val acc: ', v_acc*100, '%')\n","        print('Epoch ', e+1, ' training f1: ', t_f1*100, '%')\n","        print('Epoch ', e+1, ' val f1: ', v_f1*100, '%')"],"metadata":{"id":"6SWujgeMMsrp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_the_model(epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t52Es1ihOXIu","outputId":"2ae8e81a-7b78-439c-8d9e-6b984cad01c7","executionInfo":{"status":"ok","timestamp":1684510619759,"user_tz":-120,"elapsed":133752,"user":{"displayName":"Jose Olivert","userId":"10938111705611976671"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------EPOCH SUMMARY---------\n","Epoch  1  training loss:  0.6221428706365473\n","Epoch  1  training acc:  66.94240196078431 %\n","Epoch  1  val acc:  75.36231884057972 %\n","Epoch  1  training f1:  14.14377806622289 %\n","Epoch  1  val f1:  50.795454506113416 %\n","--------EPOCH SUMMARY---------\n","Epoch  2  training loss:  0.5186118650085786\n","Epoch  2  training acc:  81.49509803921569 %\n","Epoch  2  val acc:  82.88798309178743 %\n","Epoch  2  training f1:  67.49079356480804 %\n","Epoch  2  val f1:  74.29591704342785 %\n","--------EPOCH SUMMARY---------\n","Epoch  3  training loss:  0.44984644914374633\n","Epoch  3  training acc:  87.68382352941177 %\n","Epoch  3  val acc:  83.02385265700482 %\n","Epoch  3  training f1:  80.39506554605195 %\n","Epoch  3  val f1:  74.18362394587822 %\n","--------EPOCH SUMMARY---------\n","Epoch  4  training loss:  0.4202822069911396\n","Epoch  4  training acc:  90.25735294117648 %\n","Epoch  4  val acc:  81.18961352657004 %\n","Epoch  4  training f1:  84.9686838691624 %\n","Epoch  4  val f1:  73.20293047066502 %\n","--------EPOCH SUMMARY---------\n","Epoch  5  training loss:  0.4128249945009456\n","Epoch  5  training acc:  89.75183823529412 %\n","Epoch  5  val acc:  83.31068840579711 %\n","Epoch  5  training f1:  84.08634449294009 %\n","Epoch  5  val f1:  76.63137100700295 %\n","--------EPOCH SUMMARY---------\n","Epoch  6  training loss:  0.39931149430134716\n","Epoch  6  training acc:  91.40625 %\n","Epoch  6  val acc:  79.49124396135265 %\n","Epoch  6  training f1:  86.62987777009961 %\n","Epoch  6  val f1:  72.37517342534744 %\n"]}]},{"cell_type":"markdown","source":["## Results\n","As we can see the model learns in each iteration and we get good results. In order to improve the model we could use sentiment analysis to feed the model too."],"metadata":{"id":"UKIii3xE6g0f"}},{"cell_type":"markdown","source":["### Training the model with all the data"],"metadata":{"id":"A3WtCUhZ6rqC"}},{"cell_type":"code","source":["def train_an_epoch_full(\n","    model, \n","    train_data_loader,\n","    criterion, \n","    optimizer\n","):\n","\n","    \n","\n","    # These are the metrics that will indicate us how well it's doing the model...\n","    running_loss = 0\n","    training_acc=[]\n","    f1_training=[]\n","    steps = 0;\n","    \n","    for batch in train_data_loader:\n","        \n","        b=len(batch[\"input_ids\"])\n","        # Clean gradients...\n","        optimizer.zero_grad()\n","    \n","        # Get the information from the tokenization... (using GPU)\n","        input_ids = batch[\"input_ids\"].to(device)\n","        targets = batch[\"targets\"].to(device)\n","        attention = batch[\"attention_mask\"].to(device)\n","\n","        # get the model's predictions...\n","        outputs = model(\n","            input_ids,\n","            attention\n","            \n","        )\n","\n","        # Apply the loss function and the perform backward propagation...\n","       \n","        loss = criterion(outputs, targets)\n","       \n","        loss.backward() \n","        optimizer.step()\n","        \n","        # update the metrics...\n","\n","        pred = []\n","        real=[]\n","        for output in outputs:\n","          zero=output[0].item()\n","          one=output[1].item()\n","          if zero > one:\n","            pred.append(0)\n","          else:\n","            pred.append(1)\n","\n","        for t in targets:\n","\n","          real.append(t.item())\n","\n","        bacc=acc(real,pred)\n","        bf1= f1(real,pred)\n","        running_loss+=loss.item()\n","        training_acc.append(bacc)\n","        f1_training.append(bf1)\n","\n","        steps+=1\n","            \n","    # get the mean of the metrics...\n","    \n","    loss = running_loss/steps;\n","    t_acc=sum(training_acc)/len(training_acc)\n","    t_f1=sum(f1_training)/len(f1_training)\n","    \n","\n","    \n","    \n","    \n","\n","    return loss,t_acc,t_f1\n","\n","def train_full_model(epochs):\n","    \n","    for e in range(epochs):\n","  \n","        \n","        loss,t_acc,t_f1 = train_an_epoch_full(\n","            model, \n","            full_data_loader,\n","            criterion, \n","            optimizer\n","        )\n","        \n","        print('--------EPOCH SUMMARY---------')\n","        print('Epoch ', e+1, ' training loss: ', loss)\n","        print('Epoch ', e+1, ' training acc: ', t_acc*100, '%')\n","        \n","        print('Epoch ', e+1, ' training f1: ', t_f1*100, '%')\n","        "],"metadata":{"id":"aJkhBTeCh_2N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating the full data set"],"metadata":{"id":"G-JXv8Nm6yrA"}},{"cell_type":"code","source":["full_inputs = pd.concat([train_inputs,test_inputs])\n","full_targets = pd.concat([train_labels,test_labels])"],"metadata":{"id":"AuN8sC5f5MUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_data_loader=create_data_loader(full_inputs, full_targets,tokenizer, max_len, batch_size)"],"metadata":{"id":"I2s8ONY0iQdn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training results"],"metadata":{"id":"o4dJ2dTL67LL"}},{"cell_type":"code","source":["train_full_model(epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O15fdOHViY3J","executionInfo":{"status":"ok","timestamp":1684598983405,"user_tz":-120,"elapsed":72741,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"0be05bbb-001c-4a07-c5a5-917679729617"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------EPOCH SUMMARY---------\n","Epoch  1  training loss:  0.649702767531077\n","Epoch  1  training acc:  65.48806357649443 %\n","Epoch  1  training f1:  9.34680026503458 %\n","--------EPOCH SUMMARY---------\n","Epoch  2  training loss:  0.6339645825681233\n","Epoch  2  training acc:  65.50468591691995 %\n","Epoch  2  training f1:  7.092426768910108 %\n","--------EPOCH SUMMARY---------\n","Epoch  3  training loss:  0.6149893488202777\n","Epoch  3  training acc:  66.62075734549138 %\n","Epoch  3  training f1:  8.478538516256114 %\n","--------EPOCH SUMMARY---------\n","Epoch  4  training loss:  0.5615742795524143\n","Epoch  4  training acc:  74.32402482269505 %\n","Epoch  4  training f1:  41.64258803032905 %\n","--------EPOCH SUMMARY---------\n","Epoch  5  training loss:  0.4605344455866587\n","Epoch  5  training acc:  86.77653242147923 %\n","Epoch  5  training f1:  78.33728194908483 %\n","--------EPOCH SUMMARY---------\n","Epoch  6  training loss:  0.4227164763779867\n","Epoch  6  training acc:  88.96118287740629 %\n","Epoch  6  training f1:  82.31851369165145 %\n","--------EPOCH SUMMARY---------\n","Epoch  7  training loss:  0.3848300072408858\n","Epoch  7  training acc:  92.60701621073962 %\n","Epoch  7  training f1:  88.61791750648082 %\n","--------EPOCH SUMMARY---------\n","Epoch  8  training loss:  0.3716213284503846\n","Epoch  8  training acc:  93.44921479229991 %\n","Epoch  8  training f1:  89.9725547995921 %\n"]}]},{"cell_type":"markdown","source":["## Predictions\n","For the task 1 of HUHU we will predict the observations of the test given by the organization"],"metadata":{"id":"VX-AWcOm691u"}},{"cell_type":"code","source":["test= pd.read_csv(\"/content/drive/MyDrive/transformer/test.csv\")"],"metadata":{"id":"laF3NZPP-unr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"8p591yKW-02e","executionInfo":{"status":"ok","timestamp":1684599956111,"user_tz":-120,"elapsed":8,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"88f095e7-8194-4d62-d53a-a14fb618aafb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     index                                              tweet\n","0    52830  -Mamá en la escuela me dicen gorda -Pobresilla...\n","1    78883  No te sientas diferente, da igual si eres negr...\n","2    78926  Si esta asi.. SUPER SI.. y que se pongan celos...\n","3    61844  —Bebé ¿Me veo gorda con este vestido?\\n—¡No mi...\n","4    78830  Las mujeres solo desean 2 cosas en la vida: co...\n","..     ...                                                ...\n","773   9496  Decir que una mujer está soltera es de machist...\n","774  14026  ¿cómo un aliado se atreve a chamuyar a una ant...\n","775  12393  MENTION No hicieron nada por las mujeres, son ...\n","776  18723  Cuando llegará ese día en que las chicas organ...\n","777  92804  \"Pero cómo va a ser una presunta agresión sexu...\n","\n","[778 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-3ed4b3ea-0020-4398-a957-0a4192e14aea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>52830</td>\n","      <td>-Mamá en la escuela me dicen gorda -Pobresilla...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>78883</td>\n","      <td>No te sientas diferente, da igual si eres negr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>78926</td>\n","      <td>Si esta asi.. SUPER SI.. y que se pongan celos...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>61844</td>\n","      <td>—Bebé ¿Me veo gorda con este vestido?\\n—¡No mi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>78830</td>\n","      <td>Las mujeres solo desean 2 cosas en la vida: co...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>773</th>\n","      <td>9496</td>\n","      <td>Decir que una mujer está soltera es de machist...</td>\n","    </tr>\n","    <tr>\n","      <th>774</th>\n","      <td>14026</td>\n","      <td>¿cómo un aliado se atreve a chamuyar a una ant...</td>\n","    </tr>\n","    <tr>\n","      <th>775</th>\n","      <td>12393</td>\n","      <td>MENTION No hicieron nada por las mujeres, son ...</td>\n","    </tr>\n","    <tr>\n","      <th>776</th>\n","      <td>18723</td>\n","      <td>Cuando llegará ese día en que las chicas organ...</td>\n","    </tr>\n","    <tr>\n","      <th>777</th>\n","      <td>92804</td>\n","      <td>\"Pero cómo va a ser una presunta agresión sexu...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>778 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ed4b3ea-0020-4398-a957-0a4192e14aea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3ed4b3ea-0020-4398-a957-0a4192e14aea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3ed4b3ea-0020-4398-a957-0a4192e14aea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["test_inputs= test[\"tweet\"]"],"metadata":{"id":"_-UALZ0J_CjB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating the class to preprocess the tweets and giving them to the model"],"metadata":{"id":"yloptqgc7Gks"}},{"cell_type":"code","source":["class createTestDataset(Dataset):\n","\n","    def __init__(self, texts,  tokenizer, max_len):\n","        self.texts = texts\n","        \n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","  \n","    def __len__(self):\n","        return len(self.texts)\n","  \n","    def __getitem__(self, item):\n","        \n","        text = self.texts[item]\n","        #sentiments=self.texts[item][1:]\n","        \n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","        )\n","        input=encoding['input_ids'].flatten()\n","        \n","\n","        return {\n","            'text': text,\n","            'input_ids': input,\n","            \n","            'attention_mask': encoding['attention_mask'].flatten()\n","          \n","        }\n","\n","def create_test_data_loader(texts,  tokenizer, max_len, batch_size):\n","    \n","    ds = createTestDataset(\n","        texts=texts.to_numpy(),\n","        \n","        \n","        tokenizer=tokenizer,\n","        max_len=max_len\n","  )\n","\n","    return DataLoader(\n","        ds,\n","        batch_size=batch_size,\n","        num_workers=4\n","      )"],"metadata":{"id":"g4qHLmHG_6qs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loader= create_test_data_loader(test_inputs,tokenizer,max_len,batch_size)"],"metadata":{"id":"iY_Tm0RyAKwt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predict function\n","\n","This function uses as baseline the training function. It just get the predictions of the model and stores them in a list."],"metadata":{"id":"tmwJ4MB07NMb"}},{"cell_type":"code","source":["def predict(model, \n","    test_data_loader):\n","  with torch.no_grad():\n","        \n","        # These are the metrics that will indicate us how well it's doing the model...\n","        predictions=[]\n","        \n","        for batch in test_data_loader:\n","\n","            b= len(batch[\"input_ids\"])\n","            \n","            # Get the information from the tokenization... (using GPU)\n","            input_ids = batch[\"input_ids\"].to(device)\n","            \n","            attention = batch[\"attention_mask\"].to(device)\n","\n","            # get the model's predictions...\n","            outputs = model(\n","                input_ids,\n","                attention\n","                \n","                \n","            )\n","            \n","            \n","            for output in outputs:\n","              zero=output[0].item()\n","              one=output[1].item()\n","              if zero > one:\n","                predictions.append(0)\n","              else:\n","                predictions.append(1)\n","\n","\n","  return predictions\n","\n","        \n","\n"],"metadata":{"id":"8Kfv--R1_IWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions= predict(model,test_loader)"],"metadata":{"id":"ULQjrG02AbY2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwAb5KaAAm50","executionInfo":{"status":"ok","timestamp":1684600431784,"user_tz":-120,"elapsed":620,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"abab93cf-6099-4368-888b-a8daba9f5167"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["778"]},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","source":["### Saving the predictions in the dataframe"],"metadata":{"id":"NPCe75xR7h2X"}},{"cell_type":"code","source":["test['humor']=predictions"],"metadata":{"id":"pfKkAvxlAqzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"ZBBjV4sdAv8M","executionInfo":{"status":"ok","timestamp":1684600457999,"user_tz":-120,"elapsed":506,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"22f6a9ff-15b5-41de-e5ba-3e959f20f472"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     index                                              tweet  humor\n","0    52830  -Mamá en la escuela me dicen gorda -Pobresilla...      0\n","1    78883  No te sientas diferente, da igual si eres negr...      1\n","2    78926  Si esta asi.. SUPER SI.. y que se pongan celos...      0\n","3    61844  —Bebé ¿Me veo gorda con este vestido?\\n—¡No mi...      0\n","4    78830  Las mujeres solo desean 2 cosas en la vida: co...      0\n","..     ...                                                ...    ...\n","773   9496  Decir que una mujer está soltera es de machist...      0\n","774  14026  ¿cómo un aliado se atreve a chamuyar a una ant...      1\n","775  12393  MENTION No hicieron nada por las mujeres, son ...      1\n","776  18723  Cuando llegará ese día en que las chicas organ...      0\n","777  92804  \"Pero cómo va a ser una presunta agresión sexu...      1\n","\n","[778 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8fa61c0b-5229-4c34-adf5-c7f789ce3992\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>tweet</th>\n","      <th>humor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>52830</td>\n","      <td>-Mamá en la escuela me dicen gorda -Pobresilla...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>78883</td>\n","      <td>No te sientas diferente, da igual si eres negr...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>78926</td>\n","      <td>Si esta asi.. SUPER SI.. y que se pongan celos...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>61844</td>\n","      <td>—Bebé ¿Me veo gorda con este vestido?\\n—¡No mi...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>78830</td>\n","      <td>Las mujeres solo desean 2 cosas en la vida: co...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>773</th>\n","      <td>9496</td>\n","      <td>Decir que una mujer está soltera es de machist...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>774</th>\n","      <td>14026</td>\n","      <td>¿cómo un aliado se atreve a chamuyar a una ant...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>775</th>\n","      <td>12393</td>\n","      <td>MENTION No hicieron nada por las mujeres, son ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>776</th>\n","      <td>18723</td>\n","      <td>Cuando llegará ese día en que las chicas organ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>777</th>\n","      <td>92804</td>\n","      <td>\"Pero cómo va a ser una presunta agresión sexu...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>778 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fa61c0b-5229-4c34-adf5-c7f789ce3992')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8fa61c0b-5229-4c34-adf5-c7f789ce3992 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8fa61c0b-5229-4c34-adf5-c7f789ce3992');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["test.to_csv(\"/content/drive/MyDrive/transformer/test.csv\")"],"metadata":{"id":"PABjTlv0A1yq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once we have finished tuning the transformer for the binary classification we are going to show how tuning it for the other tasks will be.\n","\n","We will just show how the dataset class and the model class will change.\n","\n","## Using BETO for regression task"],"metadata":{"id":"lQNHqhCHUF9o"}},{"cell_type":"code","source":["inputs = data[\"tweet\"]\n","labels = data[\"mean_prejudice\"]\n","\n","\n","\n","train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n","    inputs, \n","    labels, \n","    test_size=0.2\n",")\n","\n","\n","class createDataset(Dataset):\n","\n","    def __init__(self, texts, targets, tokenizer, max_len):\n","        self.texts = texts\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","  \n","    def __len__(self):\n","        return len(self.texts)\n","  \n","    def __getitem__(self, item):\n","        \n","        text = self.texts[item]\n","        \n","        target = self.targets[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","        )\n","        input=encoding['input_ids'].flatten()\n","        \n","\n","        return {\n","            'text': text,\n","            'input_ids': input,\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'targets': torch.tensor(target, dtype=torch.float)\n","        }\n","\n","def create_data_loader(texts, labels, tokenizer, max_len, batch_size):\n","    \n","    ds = createDataset(\n","        texts=texts.to_numpy(),\n","        targets=labels.to_numpy(),\n","        \n","        tokenizer=tokenizer,\n","        max_len=max_len\n","  )\n","\n","    return DataLoader(\n","        ds,\n","        batch_size=batch_size,\n","        num_workers=4\n","      )\n","    \n","\n","class Model(nn.Module):\n","    def __init__(self, latent_dims,max_len,nhid):\n","        super(Model, self).__init__()\n","\n","        \n","        self.roberta = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n","        self.linear = nn.Linear(in_features=768, out_features=192)\n","        self.dropout=nn.Dropout(0.2)\n","        self.r = nn.ReLU()\n","        self.t=nn.Tanh()\n","        self.l = nn.Linear(in_features=192,out_features=1)\n","        \n","        \n","\n","        self.latent_dims=latent_dims\n","        self.nhid=nhid\n","\n","\n","    def forward(self, input_id,attention):\n","\n","      secuence_output = self.roberta(\n","            input_ids=input_id,\n","            attention_mask=attention\n","        )\n","      \n","      o = secuence_output.pooler_output\n","\n","      \n","\n","      o=self.linear(o)\n","      o=self.dropout(o)\n","      o=self.r(o)\n","      o=self.l(o)\n","      \n","      \n","\n","  \n","      \n","      return o.squeeze()"],"metadata":{"id":"9AOGiAx2UfBD","executionInfo":{"status":"ok","timestamp":1684840571470,"user_tz":-120,"elapsed":281,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["As we can see the only aspects we have changed is the target variable, that now is \"mean_prejudice\", and the type of this variable, instead of long type we use float.\n","\n","## Parameters"],"metadata":{"id":"hG9z3hy8UusQ"}},{"cell_type":"code","source":["batch_size = 64\n","learning_rate = 0.0001\n","criterion = nn.MSELoss().to(device)\n","criterion.requires_grad=True\n","epochs = 8\n","latentdims=2\n","nhid=128\n","max_len=60"],"metadata":{"id":"Mez344AxU_6S","executionInfo":{"status":"ok","timestamp":1684840731083,"user_tz":-120,"elapsed":253,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["We can see that all the parameters remain the same except the loss function that now will be MSELoss in order to compute de mean square error because we don´t have classes we have numerical values to predict."],"metadata":{"id":"BSvixLT5VAxb"}},{"cell_type":"markdown","source":["## Creating the model"],"metadata":{"id":"tHJfuoSEVQ4e"}},{"cell_type":"code","source":["model= Model(latentdims,max_len,nhid)\n","\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":989,"referenced_widgets":["7beb0a98db494a4a912b92673e84dfcf","b64025f5904a4fc8933017b6f65c06b3","60750663a1fa4e17bc392d9780b9ac43","2b5e8d65e2b3496883a3262d067c339b","0fe200ff8ee541f1ab553a7491a35526","dd6f9afa81084f2d9c92a15f12512090","7d5732251506465d94534cf3c97ff089","834ca82338b6409d99d56a9dfcbdfecc","17b6e12231a645da96bd0f07806f7083","683ba0531bd9462eb45e5524928f4739","0c8d5714fe3d4c96803588064835c11b"]},"id":"XjCLhtJsVNI0","executionInfo":{"status":"ok","timestamp":1684840744491,"user_tz":-120,"elapsed":11573,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"fbd27bc4-8cf3-4001-ad28-e9b8665ece1c"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7beb0a98db494a4a912b92673e84dfcf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (roberta): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (linear): Linear(in_features=768, out_features=192, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (r): ReLU()\n","  (t): Tanh()\n","  (l): Linear(in_features=192, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Creating the test and train new data loader"],"metadata":{"id":"4en6GUTwVWlY"}},{"cell_type":"code","source":["train_data_loader = create_data_loader(train_inputs, train_labels,tokenizer, max_len, batch_size)\n","\n","test_data_loader = create_data_loader(test_inputs, test_labels, tokenizer, max_len, batch_size)"],"metadata":{"id":"kN85zL0nVVl9","executionInfo":{"status":"ok","timestamp":1684840755229,"user_tz":-120,"elapsed":171,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Training function\n","\n","The only difference between this function and the function used for binary classification is the computation of the loss. Now we can´t compute accuracy nor f1 score between the outputs of our model and the targets."],"metadata":{"id":"cAHUZprZVdqv"}},{"cell_type":"code","source":["def train_an_epoch(\n","    model, \n","    train_data_loader,\n","    dev_data_loader,\n","    criterion, \n","    optimizer\n","):\n","\n","    \n","\n","    # These are the metrics that will indicate us how well it's doing the model...\n","    running_loss = 0\n","    steps = 0;\n","    mse_training=[]\n","    for batch in train_data_loader:\n","        \n","        b=len(batch[\"input_ids\"])\n","        # Clean gradients...\n","        optimizer.zero_grad()\n","    \n","        # Get the information from the tokenization... (using GPU)\n","        input_ids = batch[\"input_ids\"].to(device)\n","        targets = batch[\"targets\"].to(device)\n","        attention = batch[\"attention_mask\"].to(device)\n","\n","        # get the model's predictions...\n","        outputs = model(\n","            input_ids,\n","            attention\n","            \n","        )\n","        \n","        \n","\n","        # Apply the loss function and the perform backward propagation...\n","       \n","        loss = criterion(outputs, targets)\n","       \n","        loss.backward() \n","        optimizer.step()\n","        \n","        # update the metrics...\n","        \n","\n","        running_loss+=loss.item()\n","\n","        mse_training.append(loss.item())\n","\n","\n","\n","\n","        \n","\n","        steps+=1\n","            \n","    # get the mean of the metrics...\n","    \n","    train_mse= sum(mse_training)/len(mse_training)\n","    loss = running_loss/steps;\n","\n","    \n","    # evaluate the model with the validation data set \n","    # (\"turn off\" gradients...)\n","    with torch.no_grad():\n","        \n","        # These are the metrics that will indicate us how well it's doing the model...\n","        mse_test=[]\n","        \n","        for batch in dev_data_loader:\n","\n","            b= len(batch[\"input_ids\"])\n","            \n","            # Get the information from the tokenization... (using GPU)\n","            input_ids = batch[\"input_ids\"].to(device)\n","            targets = batch[\"targets\"].to(device)\n","            attention = batch[\"attention_mask\"].to(device)\n","\n","            # get the model's predictions...\n","            outputs = model(\n","                input_ids,\n","                attention\n","                \n","                \n","            )\n","            \n","            loss = criterion(outputs, targets)\n","\n","            \n","          \n","            mse_test.append(loss.item())\n","\n","        \n","\n","        test_mse=sum(mse_test)/len(mse_test)\n","\n","\n","       \n","    \n","\n","    return loss,train_mse,test_mse\n","\n","def train_the_model(epochs):\n","    \n","    for e in range(epochs):\n","     \n","        \n","        loss , mse_train, mse_test= train_an_epoch(\n","            model, \n","            train_data_loader,\n","            test_data_loader,\n","            criterion, \n","            optimizer\n","        )\n","        \n","        print('--------EPOCH SUMMARY---------')\n","        print('Epoch ', e+1, ' training loss: ', loss)\n","        print('Epoch ', e+1, ' training mse: ', mse_train)\n","        print('Epoch ', e+1, ' test mse: ', mse_test)"],"metadata":{"id":"kBAb9W0OVdIJ","executionInfo":{"status":"ok","timestamp":1684840847621,"user_tz":-120,"elapsed":378,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Results of the training"],"metadata":{"id":"8eYLTmEJVs8S"}},{"cell_type":"code","source":["train_the_model(epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXEZG1UqVvQ4","executionInfo":{"status":"ok","timestamp":1684840923217,"user_tz":-120,"elapsed":72948,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"2594384e-72ae-4d31-f180-3798d80ce9bd"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["--------EPOCH SUMMARY---------\n","Epoch  1  training loss:  tensor(0.9660, device='cuda:0')\n","Epoch  1  training mse:  1.4532348715207155\n","Epoch  1  test mse:  0.6873675518565707\n","--------EPOCH SUMMARY---------\n","Epoch  2  training loss:  tensor(0.9380, device='cuda:0')\n","Epoch  2  training mse:  0.6738380351487328\n","Epoch  2  test mse:  0.5976576010386149\n","--------EPOCH SUMMARY---------\n","Epoch  3  training loss:  tensor(0.8250, device='cuda:0')\n","Epoch  3  training mse:  0.511041340582511\n","Epoch  3  test mse:  0.5692977342340682\n","--------EPOCH SUMMARY---------\n","Epoch  4  training loss:  tensor(0.8628, device='cuda:0')\n","Epoch  4  training mse:  0.30672842921579585\n","Epoch  4  test mse:  0.7017213371064928\n","--------EPOCH SUMMARY---------\n","Epoch  5  training loss:  tensor(0.7886, device='cuda:0')\n","Epoch  5  training mse:  0.28821799597319436\n","Epoch  5  test mse:  0.5213635166486105\n","--------EPOCH SUMMARY---------\n","Epoch  6  training loss:  tensor(0.7389, device='cuda:0')\n","Epoch  6  training mse:  0.3071252151447184\n","Epoch  6  test mse:  0.5969605015383826\n","--------EPOCH SUMMARY---------\n","Epoch  7  training loss:  tensor(0.7980, device='cuda:0')\n","Epoch  7  training mse:  0.2805274930946967\n","Epoch  7  test mse:  0.8434068229463365\n","--------EPOCH SUMMARY---------\n","Epoch  8  training loss:  tensor(0.6799, device='cuda:0')\n","Epoch  8  training mse:  0.260995597085532\n","Epoch  8  test mse:  0.5037297242217593\n"]}]},{"cell_type":"markdown","source":["## Using BETO for multilabel classification task"],"metadata":{"id":"7E4F3vyaV9yH"}},{"cell_type":"code","source":["multi = [[float(labels[\"prejudice_woman\"]),float(labels[\"prejudice_lgbtiq\"]),float(labels[\"prejudice_inmigrant_race\"]),float(labels[\"gordofobia\"])] for _,labels in data[[\"prejudice_woman\",\"prejudice_lgbtiq\",\"prejudice_inmigrant_race\", \"gordofobia\"]].iterrows()]\n","train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n","    inputs, \n","    multi, \n","    test_size=0.2\n",")\n","\n","class createDataset(Dataset):\n","\n","    def __init__(self, texts, targets, tokenizer, max_len):\n","        self.texts = texts\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","  \n","    def __len__(self):\n","        return len(self.texts)\n","  \n","    def __getitem__(self, item):\n","        \n","        text = self.texts[item]\n","        target = self.targets[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","        )\n","        input=encoding['input_ids'].flatten()\n","        \n","\n","        return {\n","            'text': text,\n","            'input_ids': input,\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'targets': torch.tensor(target, dtype=torch.float)\n","        }\n","\n","def create_data_loader(texts, labels, tokenizer, max_len, batch_size):\n","    \n","    ds = createDataset(\n","        texts=texts.to_numpy(),\n","        targets=labels,\n","        \n","        tokenizer=tokenizer,\n","        max_len=max_len\n","  )\n","\n","    return DataLoader(\n","        ds,\n","        batch_size=batch_size,\n","        num_workers=4\n","      )\n","    \n","\n","class Model(nn.Module):\n","    def __init__(self, latent_dims,max_len,nhid):\n","        super(Model, self).__init__()\n","\n","        \n","        self.roberta = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n","        self.tanh=nn.Tanh()\n","        self.linear = nn.Linear(in_features=768, out_features=192)\n","        self.dropout=nn.Dropout(0.2)\n","        self.r = nn.ReLU()\n","        self.l = nn.Linear(in_features=192,out_features=latent_dims)\n","        self.s = nn.Sigmoid()\n","        \n","\n","        self.latent_dims=latent_dims\n","        self.nhid=nhid\n","\n","\n","    def forward(self, input_id,attention):\n","\n","      secuence_output = self.roberta(\n","            input_ids=input_id,\n","            attention_mask=attention\n","        )\n","      \n","      o = secuence_output.pooler_output\n","      o=self.linear(o)\n","      o=self.dropout(o)\n","      o=self.r(o)\n","      o=self.l(o)\n","      o=self.dropout(o)\n","      o = self.s(o)\n","\n","  \n","      \n","      return o"],"metadata":{"id":"9lL75baLWFl1","executionInfo":{"status":"ok","timestamp":1684840979788,"user_tz":-120,"elapsed":641,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["There are some changes between this classes and the ones seen before.\n","\n","Firstly we have to get a list with the labels for each tweet, including the variables of 'prejudice_woman', 'prejudice_lgtibq' etc. This list is collected in the multi variable.\n","\n","Then we can see that the type of the targets must be float too instead of long, as we did in the regression task.\n","\n","On the other hand, in the model class we have to change the last layer that will be a Sigmoid instead of Softmax and the latent_dims (labels that we have) will be 4 instead of two"],"metadata":{"id":"Af9W4lDDWR7t"}},{"cell_type":"markdown","source":["## Parameters"],"metadata":{"id":"jIQwOYKgXK0B"}},{"cell_type":"code","source":["batch_size = 64\n","learning_rate = 0.00001\n","criterion = nn.BCELoss().to(device)\n","criterion.requires_grad=True\n","epochs = 8\n","latentdims=4\n","nhid=128\n","max_len=60"],"metadata":{"id":"HCzDW6_9XKMz","executionInfo":{"status":"ok","timestamp":1684841307368,"user_tz":-120,"elapsed":187,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Now our loss function will be BCELoss and our value for latentdims will be 4 instead of 2, due to the fact that we have 4 labels to predict now."],"metadata":{"id":"3cNnJ1Y5XXHB"}},{"cell_type":"markdown","source":["### Creating the model"],"metadata":{"id":"MbF4215SXiMw"}},{"cell_type":"code","source":["model= Model(latentdims,max_len,nhid)\n","\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zAJG9_Y2XlD5","executionInfo":{"status":"ok","timestamp":1684841330888,"user_tz":-120,"elapsed":2539,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"8d9b403a-9431-4ee8-dfc9-2c678e4e7451"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (roberta): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (tanh): Tanh()\n","  (linear): Linear(in_features=768, out_features=192, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (r): ReLU()\n","  (l): Linear(in_features=192, out_features=4, bias=True)\n","  (s): Sigmoid()\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Creating the train and test new data loader"],"metadata":{"id":"gzRR61TBXpcT"}},{"cell_type":"code","source":["train_data_loader = create_data_loader(train_inputs, train_labels,tokenizer, max_len, batch_size)\n","\n","test_data_loader = create_data_loader(test_inputs, test_labels, tokenizer, max_len, batch_size)"],"metadata":{"id":"8lMcPArNXy2D","executionInfo":{"status":"ok","timestamp":1684841381365,"user_tz":-120,"elapsed":257,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Training function\n","\n","The only change is the way we compute the f1 score. For this task we will not compute the accuracy, just the loss and the f1 score."],"metadata":{"id":"rDjIIF22X4GX"}},{"cell_type":"code","source":["def train_an_epoch(\n","    model, \n","    train_data_loader,\n","    dev_data_loader,\n","    criterion, \n","    optimizer\n","):\n","\n","    \n","\n","    # These are the metrics that will indicate us how well it's doing the model...\n","    running_loss = 0\n","    \n","    f1_training=[]\n","    steps = 0;\n","    \n","    for batch in train_data_loader:\n","        \n","        b=len(batch[\"input_ids\"])\n","        # Clean gradients...\n","        optimizer.zero_grad()\n","    \n","        # Get the information from the tokenization... (using GPU)\n","        input_ids = batch[\"input_ids\"].to(device)\n","        targets = batch[\"targets\"].to(device)\n","        attention = batch[\"attention_mask\"].to(device)\n","\n","        # get the model's predictions...\n","        outputs = model(\n","            input_ids,\n","            attention\n","            \n","        )\n","\n","        # Apply the loss function and the perform backward propagation...\n","       \n","        loss = criterion(outputs, targets)\n","       \n","        loss.backward() \n","        optimizer.step()\n","        \n","        # update the metrics...\n","\n","        pred = []\n","        real=[]\n","        for output in outputs:\n","              one=output[0].item()\n","              two=output[1].item()\n","              three=output[2].item()\n","              four=output[3].item()\n","              if one >=0.50:pred.append(1)\n","              else: pred.append(0)\n","              if two >=0.50:pred.append(1)\n","              else: pred.append(0)\n","              if three >=0.50:pred.append(1)\n","              else: pred.append(0)\n","              if four >=0.50:pred.append(1)\n","              else: pred.append(0)\n","\n","        for t in targets:\n","            for elem in t:\n","\n","                real.append(elem.item())\n","\n","        \n","        bf1= f1(real,pred,average='macro')\n","        running_loss+=loss.item()\n","        \n","        f1_training.append(bf1)\n","\n","        steps+=1\n","            \n","    # get the mean of the metrics...\n","    \n","    loss = running_loss/steps;\n","    \n","    t_f1=sum(f1_training)/len(f1_training)\n","    \n","    \n","    \n","    # evaluate the model with the validation data set \n","    # (\"turn off\" gradients...)\n","    with torch.no_grad():\n","        \n","        # These are the metrics that will indicate us how well it's doing the model...\n","        test_acc=[];\n","        steps_val=0;\n","        f1_test=[]\n","        \n","        for batch in dev_data_loader:\n","\n","            b= len(batch[\"input_ids\"])\n","            \n","            # Get the information from the tokenization... (using GPU)\n","            input_ids = batch[\"input_ids\"].to(device)\n","            targets = batch[\"targets\"].to(device)\n","            attention = batch[\"attention_mask\"].to(device)\n","\n","            # get the model's predictions...\n","            outputs = model(\n","                input_ids,\n","                attention\n","                \n","                \n","            )\n","            \n","            \n","            pred = []\n","            real=[]\n","            for output in outputs:\n","              one=output[0].item()\n","              two=output[1].item()\n","              three=output[2].item()\n","              four=output[3].item()\n","              if one >=0.50:pred.append(1)\n","              else: pred.append(0)\n","              if two >=0.50:pred.append(1)\n","              else: pred.append(0)\n","              if three >=0.50:pred.append(1)\n","              else: pred.append(0)\n","              if four >=0.50:pred.append(1)\n","              else: pred.append(0)\n","\n","            for t in targets:\n","              for elem in t:\n","\n","                real.append(elem.item())\n","\n","            \n","            bf1= f1(real,pred,average='macro')\n","            \n","            f1_test.append(bf1)\n","\n","\n","        \n","        v_f1= sum(f1_test)/len(f1_test)\n","    \n","\n","    return loss,t_f1,v_f1\n","\n","def train_the_model(epochs):\n","    \n","    for e in range(epochs):\n","      \n","        loss,t_f1,v_f1 = train_an_epoch(\n","            model, \n","            train_data_loader,\n","            test_data_loader,\n","            criterion, \n","            optimizer\n","        )\n","        \n","        print('--------EPOCH SUMMARY---------')\n","        print('Epoch ', e+1, ' training loss: ', loss)\n","        \n","        print('Epoch ', e+1, ' training f1: ', t_f1*100, '%')\n","        print('Epoch ', e+1, ' val f1: ', v_f1*100, '%')"],"metadata":{"id":"SNSINJvTXy7L","executionInfo":{"status":"ok","timestamp":1684841439258,"user_tz":-120,"elapsed":348,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Results of the training"],"metadata":{"id":"5zT6k8eMYFKm"}},{"cell_type":"code","source":["train_the_model(epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"me9KczRNYHPq","executionInfo":{"status":"ok","timestamp":1684841535689,"user_tz":-120,"elapsed":72111,"user":{"displayName":"Pepe Olivert","userId":"09214730254765494077"}},"outputId":"d521b5b2-0935-46c8-ec70-7823c337226f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["--------EPOCH SUMMARY---------\n","Epoch  1  training loss:  0.5929780321962693\n","Epoch  1  training f1:  58.179443155442534 %\n","Epoch  1  val f1:  58.484370460257736 %\n","--------EPOCH SUMMARY---------\n","Epoch  2  training loss:  0.5002417546861312\n","Epoch  2  training f1:  62.948629578839046 %\n","Epoch  2  val f1:  67.08940802907843 %\n","--------EPOCH SUMMARY---------\n","Epoch  3  training loss:  0.3811105603680891\n","Epoch  3  training f1:  75.61173546061566 %\n","Epoch  3  val f1:  76.412124915779 %\n","--------EPOCH SUMMARY---------\n","Epoch  4  training loss:  0.2939667969065554\n","Epoch  4  training f1:  80.64925482196446 %\n","Epoch  4  val f1:  78.31196971983067 %\n","--------EPOCH SUMMARY---------\n","Epoch  5  training loss:  0.24629126883604946\n","Epoch  5  training f1:  82.25250938456816 %\n","Epoch  5  val f1:  78.53795581443893 %\n","--------EPOCH SUMMARY---------\n","Epoch  6  training loss:  0.22323094702818813\n","Epoch  6  training f1:  82.00563690270758 %\n","Epoch  6  val f1:  76.61019370998278 %\n","--------EPOCH SUMMARY---------\n","Epoch  7  training loss:  0.20953537742881215\n","Epoch  7  training f1:  81.84452924859434 %\n","Epoch  7  val f1:  80.5524245449661 %\n","--------EPOCH SUMMARY---------\n","Epoch  8  training loss:  0.19074802933370366\n","Epoch  8  training f1:  83.14153833535465 %\n","Epoch  8  val f1:  79.87121626129108 %\n"]}]}]}